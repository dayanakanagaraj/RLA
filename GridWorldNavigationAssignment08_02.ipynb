{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b8a020-91b2-480b-9b4e-a047d8340157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aae09d9-bf81-406f-a694-bcf7435e8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid World parameters\n",
    "GRID_SIZE = 5\n",
    "START = (0, 0)\n",
    "GOAL = (4, 4)\n",
    "OBSTACLE_COUNT = 3  # Number of random obstacles\n",
    "ACTIONS = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "EPISODES = 500  # Training episodes\n",
    "ALPHA = 0.1  # Learning rate\n",
    "GAMMA = 0.9  # Discount factor\n",
    "EPSILON = 0.1  # Exploration factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7492ef31-0a9d-4890-a5a6-01f71796d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table\n",
    "Q_table = np.zeros((GRID_SIZE, GRID_SIZE, len(ACTIONS)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa457efb-d1f4-4f10-a9c8-a67a244e3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place obstacles at random locations\n",
    "def generate_obstacles():\n",
    "    obstacles = set()\n",
    "    while len(obstacles) < OBSTACLE_COUNT:\n",
    "        pos = (random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1))\n",
    "        if pos != START and pos != GOAL:\n",
    "            obstacles.add(pos)\n",
    "    return obstacles\n",
    "\n",
    "OBSTACLES = generate_obstacles()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdf617f-f3e8-4d30-9710-69a1e5bd0959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function\n",
    "def get_reward(state):\n",
    "    if state == GOAL:\n",
    "        return 10\n",
    "    elif state in OBSTACLES:\n",
    "        return -5\n",
    "    return -1  # Small penalty for each step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0289377e-ec29-40fe-889e-86c7ce0ab70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get next state based on action\n",
    "def get_next_state(state, action):\n",
    "    x, y = state\n",
    "    if action == 'UP':\n",
    "        x = max(0, x - 1)\n",
    "    elif action == 'DOWN':\n",
    "        x = min(GRID_SIZE - 1, x + 1)\n",
    "    elif action == 'LEFT':\n",
    "        y = max(0, y - 1)\n",
    "    elif action == 'RIGHT':\n",
    "        y = min(GRID_SIZE - 1, y + 1)\n",
    "    return (x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9b094d-74b6-4e27-b695-cf8a6704da75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose action using epsilon-greedy strategy\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < EPSILON:\n",
    "        return random.choice(ACTIONS)  # Explore\n",
    "    else:\n",
    "        return ACTIONS[np.argmax(Q_table[state[0], state[1]])]  # Exploit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5dc107-091b-4ab5-8d90-454cc4123428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "for episode in range(EPISODES):\n",
    "    state = START\n",
    "    while state != GOAL:\n",
    "        action = choose_action(state)\n",
    "        next_state = get_next_state(state, action)\n",
    "        reward = get_reward(next_state)\n",
    "\n",
    "        # Q-learning update rule\n",
    "        action_index = ACTIONS.index(action)\n",
    "        best_next_q = np.max(Q_table[next_state[0], next_state[1]])\n",
    "        Q_table[state[0], state[1], action_index] += ALPHA * (reward + GAMMA * best_next_q - Q_table[state[0], state[1], action_index])\n",
    "\n",
    "        # Move to next state\n",
    "        state = next_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b87abe99-d3b3-493f-8aaa-aadefe4d82d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Q-table:\n",
      "[[[-1.43326060e+00 -4.34062000e-01 -1.47999834e+00 -5.15679173e-01]\n",
      "  [-2.35027744e+00  6.27373967e-01 -2.54375246e+00 -2.99874539e+00]\n",
      "  [-9.95000000e-01 -8.38077602e-01 -7.52695402e-01 -7.08772010e-01]\n",
      "  [-6.79346521e-01 -7.48869959e-01 -9.93557030e-01 -1.38173900e+00]\n",
      "  [-5.00000000e-01 -3.05830900e-01 -2.43910000e-01 -5.00000000e-01]]\n",
      "\n",
      " [[-1.49545090e+00  3.59062498e-01 -4.71823790e-01  6.28820000e-01]\n",
      "  [-5.72039275e-01  1.80980000e+00 -4.61090657e-01 -2.27761694e+00]\n",
      "  [-1.85855907e+00  3.12138078e+00 -4.37362944e-01 -6.04116054e-01]\n",
      "  [-5.43657824e-01  5.51979133e-01 -1.36481000e+00 -5.47626203e-01]\n",
      "  [-9.50000000e-01 -2.52860657e-01 -4.26010253e-01 -4.83089539e-01]]\n",
      "\n",
      " [[-1.55501225e+00 -1.81232153e+00 -9.22399656e-01  1.80854969e+00]\n",
      "  [ 6.05120511e-01  3.07111125e+00  5.90642516e-01  3.12200000e+00]\n",
      "  [-2.20422004e+00  4.58000000e+00  1.77771476e+00  3.88929262e+00]\n",
      "  [-3.38075004e-01  6.05456478e+00 -5.47199399e-01 -3.28122100e-01]\n",
      "  [-1.90000000e-01  2.72999682e+00 -1.09000000e-01 -1.00000000e-01]]\n",
      "\n",
      " [[-1.31007941e+00 -1.20212465e+00 -1.22478977e+00 -3.43180142e-01]\n",
      "  [ 5.21589707e-01 -3.39661215e-01 -1.04553092e+00  4.57943037e+00]\n",
      "  [ 3.09686493e+00  6.20000000e+00  3.02743129e+00  5.35647773e+00]\n",
      "  [ 4.26702059e-01  2.02949000e+00  7.46908569e-01  7.99893783e+00]\n",
      "  [-6.41485324e-03  9.99989710e+00  1.83566014e+00  2.36337232e+00]]\n",
      "\n",
      " [[-9.35977650e-01 -8.64827525e-01 -8.64827525e-01  2.47246489e-01]\n",
      "  [-1.47903005e-01 -3.54452001e-02 -7.21029628e-01  6.02674791e+00]\n",
      "  [ 4.47294553e+00  5.95580151e+00  3.79769854e+00  8.00000000e+00]\n",
      "  [ 5.96973885e+00  7.84338546e+00  6.15773304e+00  1.00000000e+01]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# Print final Q-table\n",
    "print(\"Trained Q-table:\")\n",
    "print(Q_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210657eb-6935-4cdc-b45a-f74dec149074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
